---

# Generated by AI

# NutScrape - Distributed Web Scraping Platform

A high-performance, scalable web scraping platform built with Nest.js, featuring three microservices: API, Job Manager, and Scraper. Built for production use with Kubernetes deployment support, proxy capabilities, and both static and dynamic scraping modes.

## üèóÔ∏è Architecture

This project implements a distributed microservices architecture with three core services:

- **API Service** (`nutscrapi`): RESTful API for creating and retrieving scrape jobs
- **Job Manager** (`nutscrapejob`): Validates, persists, and enqueues scraping jobs using BullMQ
- **Scraper** (`nutscraper`): Consumes queued jobs and performs the actual web scraping

### Technology Stack

- **Framework**: Nest.js (Node.js)
- **Queue System**: BullMQ with Redis
- **Database**: MongoDB with Mongoose
- **Web Scraping**: Puppeteer (dynamic) + Axios (static)
- **Containerization**: Docker
- **Package Manager**: pnpm
- **API Documentation**: Swagger/OpenAPI

## üöÄ Features

### Scraping Capabilities

- **Static Scraping**: Fast HTTP requests using Axios for simple content
- **Dynamic Scraping**: Full browser automation with Puppeteer for JavaScript-heavy sites
- **Proxy Support**: HTTP, HTTPS, and SOCKS5 proxy support
- **User Agent Management**: Predefined user agents for different browsers and tools
- **Redirect Handling**: Configurable redirect following with limits
- **Resource Blocking**: Optional blocking of images, CSS, and fonts for faster scraping

### Reliability & Performance

- **Retry Logic**: Intelligent retry mechanism with exponential backoff
- **Error Handling**: Comprehensive error analysis and categorization
- **Queue Management**: Robust job queuing with BullMQ
- **Health Checks**: Built-in health monitoring endpoints
- **Rate Limiting**: Request throttling capabilities

### Developer Experience

- **API Documentation**: Interactive Swagger documentation
- **Type Safety**: Full TypeScript implementation
- **Validation**: Request validation with class-validator
- **Logging**: Structured logging across all services
- **Testing**: Jest testing framework setup

## üìã Prerequisites

- Node.js 20+
- pnpm
- MongoDB
- Redis
- Docker (optional)
- Kubernetes (for production deployment)

## üõ†Ô∏è Installation

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd nutscrapi
   ```

2. **Install dependencies**

   ```bash
   pnpm install
   ```

3. **Set up environment variables**
   Create `.env` files for each service with the following variables:

   **API Service** (`.env`):

   ```env
   PORT=3000
   MONGODB_URI=mongodb://localhost:27017/nutscrapi
   REDIS_HOST=localhost
   REDIS_PORT=6379
   ```

   **Job Manager** (`.env`):

   ```env
   MONGODB_URI=mongodb://localhost:27017/nutscrapi
   REDIS_HOST=localhost
   REDIS_PORT=6379
   ```

   **Scraper** (`.env`):

   ```env
   MONGODB_URI=mongodb://localhost:27017/nutscrapi
   REDIS_HOST=localhost
   REDIS_PORT=6379
   ```

4. **Start services**

   ```bash
   # Start all services in development mode
   pnpm run start:dev

   # Or start individual services
   pnpm run start:dev nutscrapi
   pnpm run start:dev nutscrapejob
   pnpm run start:dev nutscraper
   ```

### Individual service builds

```bash
# API Service
docker build -f apps/nutscrapi/Dockerfile -t nutscrapi:latest .

# Job Manager
docker build -f apps/nutscrapejob/Dockerfile -t nutscrapejob:latest .

# Scraper
docker build -f apps/nutscraper/Dockerfile -t nutscraper:latest .
```

## üìö API Documentation

Once the API service is running, visit `http://localhost:3000/docs` for interactive Swagger documentation.

### Key Endpoints

#### Static Scraping

```http
POST /scrape/static
Content-Type: application/json

{
  "url": "https://example.com",
  "userAgent": "CHROME",
  "followRedirects": true,
  "maxRedirects": 5,
  "retries": 3,
  "proxy": {
    "address": "proxy.example.com",
    "port": 8080,
    "type": "http",
    "username": "user",
    "password": "pass"
  }
}
```

#### Dynamic Scraping

```http
POST /scrape/dynamic
Content-Type: application/json

{
  "url": "https://spa-app.com",
  "userAgent": "CHROME",
  "waitUntil": "SMART",
  "waitForSelector": ".dynamic-content",
  "waitForTimeout": 30000,
  "blockImages": false,
  "blockCSS": false,
  "blockFonts": false,
  "retries": 3
}
```

#### Get Scrape Result

```http
GET /scrape/{jobId}
```

### User Agent Options

- **Browser Agents**: `CHROME`, `FIREFOX`, `SAFARI`, `EDGE`
- **Mobile Agents**: `CHROME_MOBILE`, `SAFARI_MOBILE`
- **Tool Agents**: `CURL`, `NODE`, `PYTHON`, `GO`

### Wait Strategies (Dynamic Scraping)

- **QUICK**: Wait for DOMContentLoaded (fastest)
- **STANDARD**: Wait for load event (default)
- **COMPLETE**: Wait for networkidle0 (most complete)
- **SMART**: Wait for networkidle2 (balanced)

## üîß Development

### Project Structure

```
nutscrapi/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ nutscrapi/          # API service
‚îÇ   ‚îú‚îÄ‚îÄ nutscrapejob/       # Job manager service
‚îÇ   ‚îî‚îÄ‚îÄ nutscraper/         # Scraper service
‚îú‚îÄ‚îÄ libs/
‚îÇ   ‚îî‚îÄ‚îÄ nutscrapedb/        # Shared database models and utilities
‚îú‚îÄ‚îÄ dist/                   # Built applications
‚îî‚îÄ‚îÄ package.json
```

### Available Scripts

```bash
# Development
pnpm run start:dev          # Start all services in watch mode
pnpm run start:debug        # Start with debugging enabled

### Adding New Features

1. **API Endpoints**: Add controllers in `apps/nutscrapi/src/`
2. **Job Processing**: Add processors in `apps/nutscrapejob/src/`
3. **Scraping Logic**: Extend services in `apps/nutscraper/src/`
4. **Shared Models**: Add to `libs/nutscrapedb/src/`

## üîç Monitoring & Health Checks

### Health Endpoints

- **API Service**: `GET /health`
- **Job Manager**: Built-in BullMQ monitoring
- **Scraper**: Service-specific health checks

## üö® Error Handling

The platform includes comprehensive error handling:

- **Retry Logic**: Automatic retries with exponential backoff
- **Error Classification**: Categorization of retryable vs non-retryable errors
- **Graceful Degradation**: Fallback mechanisms for service failures
- **Circuit Breakers**: Protection against cascading failures
```
